{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Province_State</th>\n",
       "      <th>Country_Region</th>\n",
       "      <th>Date</th>\n",
       "      <th>ConfirmedCases</th>\n",
       "      <th>Fatalities</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>2020-01-22</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>2020-01-23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>2020-01-24</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>2020-01-25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>2020-01-26</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id Province_State Country_Region        Date  ConfirmedCases  Fatalities\n",
       "0   1            NaN    Afghanistan  2020-01-22             0.0         0.0\n",
       "1   2            NaN    Afghanistan  2020-01-23             0.0         0.0\n",
       "2   3            NaN    Afghanistan  2020-01-24             0.0         0.0\n",
       "3   4            NaN    Afghanistan  2020-01-25             0.0         0.0\n",
       "4   5            NaN    Afghanistan  2020-01-26             0.0         0.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>ConfirmedCases</th>\n",
       "      <th>Fatalities</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>22644.000000</td>\n",
       "      <td>22644.000000</td>\n",
       "      <td>22644.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>16355.000000</td>\n",
       "      <td>655.267002</td>\n",
       "      <td>29.015412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>9451.983632</td>\n",
       "      <td>5428.632429</td>\n",
       "      <td>382.138505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>8169.750000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>16355.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>24540.250000</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>32709.000000</td>\n",
       "      <td>126168.000000</td>\n",
       "      <td>15362.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Id  ConfirmedCases    Fatalities\n",
       "count  22644.000000    22644.000000  22644.000000\n",
       "mean   16355.000000      655.267002     29.015412\n",
       "std     9451.983632     5428.632429    382.138505\n",
       "min        1.000000        0.000000      0.000000\n",
       "25%     8169.750000        0.000000      0.000000\n",
       "50%    16355.000000        0.000000      0.000000\n",
       "75%    24540.250000       51.000000      0.000000\n",
       "max    32709.000000   126168.000000  15362.000000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "US                  3996\n",
       "China               2442\n",
       "Canada               888\n",
       "United Kingdom       740\n",
       "France               740\n",
       "                    ... \n",
       "Papua New Guinea      74\n",
       "Timor-Leste           74\n",
       "Croatia               74\n",
       "Brazil                74\n",
       "Albania               74\n",
       "Name: Country_Region, Length: 180, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Country_Region'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "China                  2248\n",
       "US                     1196\n",
       "Canada                  208\n",
       "France                  187\n",
       "Australia               186\n",
       "                       ... \n",
       "Antigua and Barbuda       2\n",
       "Guinea-Bissau             2\n",
       "Fiji                      1\n",
       "Angola                    1\n",
       "Liberia                   1\n",
       "Name: Country_Region, Length: 159, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['ConfirmedCases']>=10]['Country_Region'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52       2020-03-14\n",
       "53       2020-03-15\n",
       "54       2020-03-16\n",
       "55       2020-03-17\n",
       "56       2020-03-18\n",
       "            ...    \n",
       "22565    2020-03-31\n",
       "22566    2020-04-01\n",
       "22567    2020-04-02\n",
       "22568    2020-04-03\n",
       "22569    2020-04-04\n",
       "Name: Date, Length: 7736, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['ConfirmedCases']>=10]['Date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "74"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Date'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "180"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Country_Region'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA TRANSFORMATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NaN values imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Province_State'] = df['Province_State'].fillna('unknown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Province_State</th>\n",
       "      <th>Country_Region</th>\n",
       "      <th>Date</th>\n",
       "      <th>ConfirmedCases</th>\n",
       "      <th>Fatalities</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>unknown</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>2020-01-22</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>unknown</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>2020-01-23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>unknown</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>2020-01-24</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>unknown</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>2020-01-25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>unknown</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>2020-01-26</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id Province_State Country_Region        Date  ConfirmedCases  Fatalities\n",
       "0   1        unknown    Afghanistan  2020-01-22             0.0         0.0\n",
       "1   2        unknown    Afghanistan  2020-01-23             0.0         0.0\n",
       "2   3        unknown    Afghanistan  2020-01-24             0.0         0.0\n",
       "3   4        unknown    Afghanistan  2020-01-25             0.0         0.0\n",
       "4   5        unknown    Afghanistan  2020-01-26             0.0         0.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22644"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Country_Region'] = df['Country_Region'].astype('category')\n",
    "df['Province_State'] = df['Province_State'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping_region = dict(zip(df['Country_Region'].values,df['Country_Region'].cat.codes))\n",
    "mapping_province = dict(zip(df['Province_State'].values,df['Province_State'].cat.codes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "def slice_data(df,length=5):\n",
    "    X = []\n",
    "    y1 = []\n",
    "    y2 = []\n",
    "    X_cat1 = []\n",
    "    X_cat2 = []\n",
    "    for i in range(len(df)-length):\n",
    "            X1 = df['ConfirmedCases'].values[i:length+i].reshape(-1,1)\n",
    "            X2 = df['Fatalities'].values[i:length+i].reshape(-1,1)\n",
    "            X.append(np.hstack((X1,X2)))\n",
    "            y1.append(df['ConfirmedCases'].values[length+i])\n",
    "            y2.append(df['Fatalities'].values[length+i])\n",
    "            X_cat1.append(tf.keras.utils.to_categorical(\n",
    "                mapping_region[df['Country_Region'].values[i]],len(mapping_region)))\n",
    "            X_cat2.append(tf.keras.utils.to_categorical(\n",
    "                mapping_province[df['Province_State'].values[i]],len(mapping_province)))\n",
    "    return np.array(X),\\\n",
    "np.concatenate((np.array(y1).reshape(-1,1),np.array(y2).reshape(-1,1)),axis=1),\\\n",
    "np.concatenate((np.array(X_cat1), np.array(X_cat2)),axis=1)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_lstm,y,X_dense = slice_data(df,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22640, 22640, 22640)"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_lstm), len(y),len(X_dense)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.]],\n",
       "\n",
       "       [[0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.]],\n",
       "\n",
       "       [[0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[7., 1.],\n",
       "        [7., 1.],\n",
       "        [8., 1.],\n",
       "        [8., 1.]],\n",
       "\n",
       "       [[7., 1.],\n",
       "        [8., 1.],\n",
       "        [8., 1.],\n",
       "        [9., 1.]],\n",
       "\n",
       "       [[8., 1.],\n",
       "        [8., 1.],\n",
       "        [9., 1.],\n",
       "        [9., 1.]]])"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_dense = X_dense.reshape(X_dense.shape[0],1,X_dense.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22640, 4, 2)"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_lstm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       ...,\n",
       "       [9., 1.],\n",
       "       [9., 1.],\n",
       "       [9., 1.]])"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22640, 2)"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22640, 1, 311)"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_dense.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(len(X_dense)*0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20376"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_dense_train, X_lstm_train, y_train = X_dense[:train_size],X_lstm[:train_size], y[:train_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_dense_test, X_lstm_test, y_test = X_dense[train_size:],X_lstm[train_size:], y[train_size:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:<tensorflow.python.keras.layers.recurrent.UnifiedLSTM object at 0x7faac571fb50>: Note that this layer is not optimized for performance. Please use tf.keras.layers.CuDNNLSTM for better performance on GPU.\n",
      "WARNING:tensorflow:<tensorflow.python.keras.layers.recurrent.UnifiedLSTM object at 0x7faac7c85f50>: Note that this layer is not optimized for performance. Please use tf.keras.layers.CuDNNLSTM for better performance on GPU.\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "#first input \n",
    "lstm_input = tf.keras.layers.Input((X_lstm.shape[1],X_lstm.shape[2]))\n",
    "lstm_block1 = tf.keras.layers.LSTM(256,return_sequences=True)(lstm_input)\n",
    "lstm_block2 = tf.keras.layers.LSTM(128)(lstm_block1)\n",
    "reshape_layer = tf.keras.layers.Reshape((1,128))(lstm_block2)\n",
    "\n",
    "#second input\n",
    "dense_input = tf.keras.layers.Input((X_dense.shape[1],X_dense.shape[2]))\n",
    "dense_layer1 = tf.keras.layers.Dense(1024,activation='relu')(dense_input)\n",
    "dropout_layer1 = tf.keras.layers.Dropout(0.3)(dense_layer1)\n",
    "dense_layer2 = tf.keras.layers.Dense(128,activation='relu')(dropout_layer1)\n",
    "\n",
    "#embedd everything together\n",
    "concat_layer = tf.keras.layers.add([reshape_layer,dense_layer2])\n",
    "flatten_layer = tf.keras.layers.Flatten()(concat_layer)\n",
    "final_dense = tf.keras.layers.Dense(1024,activation='relu')(flatten_layer)\n",
    "output_layer = tf.keras.layers.Dense(2,activation='relu')(flatten_layer)\n",
    "\n",
    "#Model\n",
    "model = tf.keras.Model(inputs=[lstm_input,dense_input],outputs=output_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='Adam',loss=tf.keras.losses.MeanSquaredLogarithmicError())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', patience=15, verbose=1, factor=0.6),\n",
    "             tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=20)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 4, 2)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 1, 311)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "unified_lstm (UnifiedLSTM)      (None, 4, 256)       265216      input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1, 1024)      319488      input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "unified_lstm_1 (UnifiedLSTM)    (None, 128)          197120      unified_lstm[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 1, 1024)      0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "reshape (Reshape)               (None, 1, 128)       0           unified_lstm_1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1, 128)       131200      dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 1, 128)       0           reshape[0][0]                    \n",
      "                                                                 dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 128)          0           add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 2)            258         flatten[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 913,282\n",
      "Trainable params: 913,282\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20376 samples, validate on 2264 samples\n",
      "Epoch 1/250\n",
      "20376/20376 [==============================] - 3s 164us/sample - loss: 1.3163 - val_loss: 0.7059\n",
      "Epoch 2/250\n",
      "20376/20376 [==============================] - 3s 139us/sample - loss: 0.9046 - val_loss: 0.6283\n",
      "Epoch 3/250\n",
      "20376/20376 [==============================] - 3s 146us/sample - loss: 0.8084 - val_loss: 0.5816\n",
      "Epoch 4/250\n",
      "20376/20376 [==============================] - 3s 147us/sample - loss: 0.7544 - val_loss: 0.5913\n",
      "Epoch 5/250\n",
      "20376/20376 [==============================] - 3s 137us/sample - loss: 0.7159 - val_loss: 0.5431\n",
      "Epoch 6/250\n",
      "20376/20376 [==============================] - 5s 231us/sample - loss: 0.6939 - val_loss: 0.5647\n",
      "Epoch 7/250\n",
      "20376/20376 [==============================] - 3s 156us/sample - loss: 0.6699 - val_loss: 0.5501\n",
      "Epoch 8/250\n",
      "20376/20376 [==============================] - 8s 377us/sample - loss: 0.6521 - val_loss: 0.5291\n",
      "Epoch 9/250\n",
      "20376/20376 [==============================] - 3s 144us/sample - loss: 0.6375 - val_loss: 0.5393\n",
      "Epoch 10/250\n",
      "20376/20376 [==============================] - 4s 187us/sample - loss: 0.6365 - val_loss: 0.5347\n",
      "Epoch 11/250\n",
      "20376/20376 [==============================] - 3s 149us/sample - loss: 0.6215 - val_loss: 0.5437\n",
      "Epoch 12/250\n",
      "20376/20376 [==============================] - 3s 146us/sample - loss: 0.6070 - val_loss: 0.5007\n",
      "Epoch 13/250\n",
      "20376/20376 [==============================] - 3s 151us/sample - loss: 0.6001 - val_loss: 0.5136\n",
      "Epoch 14/250\n",
      "20376/20376 [==============================] - 3s 144us/sample - loss: 0.5961 - val_loss: 0.5135\n",
      "Epoch 15/250\n",
      "20376/20376 [==============================] - 3s 146us/sample - loss: 0.5894 - val_loss: 0.5352\n",
      "Epoch 16/250\n",
      "20376/20376 [==============================] - 3s 149us/sample - loss: 0.5828 - val_loss: 0.5232\n",
      "Epoch 17/250\n",
      "20376/20376 [==============================] - 4s 175us/sample - loss: 0.5739 - val_loss: 0.5467\n",
      "Epoch 18/250\n",
      "20376/20376 [==============================] - 3s 161us/sample - loss: 0.5660 - val_loss: 0.5727\n",
      "Epoch 19/250\n",
      "20376/20376 [==============================] - 3s 153us/sample - loss: 0.5602 - val_loss: 0.5075\n",
      "Epoch 20/250\n",
      "20376/20376 [==============================] - 3s 170us/sample - loss: 0.5503 - val_loss: 0.4950\n",
      "Epoch 21/250\n",
      "20376/20376 [==============================] - 3s 156us/sample - loss: 0.5377 - val_loss: 0.5306\n",
      "Epoch 22/250\n",
      "20376/20376 [==============================] - 3s 158us/sample - loss: 0.5345 - val_loss: 0.4999\n",
      "Epoch 23/250\n",
      "20376/20376 [==============================] - 3s 162us/sample - loss: 0.5256 - val_loss: 0.4748\n",
      "Epoch 24/250\n",
      "20376/20376 [==============================] - 3s 153us/sample - loss: 0.5238 - val_loss: 0.4963\n",
      "Epoch 25/250\n",
      "20376/20376 [==============================] - 3s 164us/sample - loss: 0.5139 - val_loss: 0.5143\n",
      "Epoch 26/250\n",
      "20376/20376 [==============================] - 3s 160us/sample - loss: 0.5158 - val_loss: 0.4688\n",
      "Epoch 27/250\n",
      "20376/20376 [==============================] - 3s 158us/sample - loss: 0.4967 - val_loss: 0.4157\n",
      "Epoch 28/250\n",
      "20376/20376 [==============================] - 3s 168us/sample - loss: 0.4844 - val_loss: 0.4209\n",
      "Epoch 29/250\n",
      "20376/20376 [==============================] - 3s 153us/sample - loss: 0.4829 - val_loss: 0.4126\n",
      "Epoch 30/250\n",
      "20376/20376 [==============================] - 3s 143us/sample - loss: 0.4807 - val_loss: 0.4043\n",
      "Epoch 31/250\n",
      "20376/20376 [==============================] - 3s 143us/sample - loss: 0.4745 - val_loss: 0.3914\n",
      "Epoch 32/250\n",
      "20376/20376 [==============================] - 3s 143us/sample - loss: 0.4707 - val_loss: 0.3886\n",
      "Epoch 33/250\n",
      "20376/20376 [==============================] - 3s 150us/sample - loss: 0.4675 - val_loss: 0.3893\n",
      "Epoch 34/250\n",
      "20376/20376 [==============================] - 3s 148us/sample - loss: 0.4614 - val_loss: 0.3836\n",
      "Epoch 35/250\n",
      "20376/20376 [==============================] - 3s 150us/sample - loss: 0.4567 - val_loss: 0.3841\n",
      "Epoch 36/250\n",
      "20376/20376 [==============================] - 3s 151us/sample - loss: 0.4594 - val_loss: 0.3840\n",
      "Epoch 37/250\n",
      "20376/20376 [==============================] - 3s 143us/sample - loss: 0.4539 - val_loss: 0.3797\n",
      "Epoch 38/250\n",
      "20376/20376 [==============================] - 3s 145us/sample - loss: 0.4512 - val_loss: 0.3791\n",
      "Epoch 39/250\n",
      "20376/20376 [==============================] - 3s 144us/sample - loss: 0.4505 - val_loss: 0.3853\n",
      "Epoch 40/250\n",
      "20376/20376 [==============================] - 3s 146us/sample - loss: 0.4484 - val_loss: 0.3782\n",
      "Epoch 41/250\n",
      "20376/20376 [==============================] - 3s 150us/sample - loss: 0.4486 - val_loss: 0.3760\n",
      "Epoch 42/250\n",
      "20376/20376 [==============================] - 3s 150us/sample - loss: 0.4459 - val_loss: 0.3802\n",
      "Epoch 43/250\n",
      "20376/20376 [==============================] - 4s 174us/sample - loss: 0.4452 - val_loss: 0.3813\n",
      "Epoch 44/250\n",
      "20376/20376 [==============================] - 3s 169us/sample - loss: 0.4415 - val_loss: 0.3771\n",
      "Epoch 45/250\n",
      "20376/20376 [==============================] - 3s 155us/sample - loss: 0.4412 - val_loss: 0.3735\n",
      "Epoch 46/250\n",
      "20376/20376 [==============================] - 4s 173us/sample - loss: 0.4393 - val_loss: 0.3716\n",
      "Epoch 47/250\n",
      "20376/20376 [==============================] - 3s 166us/sample - loss: 0.4363 - val_loss: 0.3710\n",
      "Epoch 48/250\n",
      "20376/20376 [==============================] - 3s 165us/sample - loss: 0.4331 - val_loss: 0.3708\n",
      "Epoch 49/250\n",
      "20376/20376 [==============================] - 3s 168us/sample - loss: 0.4367 - val_loss: 0.3723\n",
      "Epoch 50/250\n",
      "20376/20376 [==============================] - 3s 163us/sample - loss: 0.4364 - val_loss: 0.3677\n",
      "Epoch 51/250\n",
      "20376/20376 [==============================] - 3s 157us/sample - loss: 0.4347 - val_loss: 0.3635\n",
      "Epoch 52/250\n",
      "20376/20376 [==============================] - 6s 313us/sample - loss: 0.4300 - val_loss: 0.3726\n",
      "Epoch 53/250\n",
      "20376/20376 [==============================] - 9s 434us/sample - loss: 0.4293 - val_loss: 0.3877\n",
      "Epoch 54/250\n",
      "20376/20376 [==============================] - 9s 435us/sample - loss: 0.4278 - val_loss: 0.3661\n",
      "Epoch 55/250\n",
      "20376/20376 [==============================] - 4s 202us/sample - loss: 0.4305 - val_loss: 0.3673\n",
      "Epoch 56/250\n",
      "20376/20376 [==============================] - 4s 188us/sample - loss: 0.4327 - val_loss: 0.3815\n",
      "Epoch 57/250\n",
      "20376/20376 [==============================] - 4s 188us/sample - loss: 0.4315 - val_loss: 0.3619\n",
      "Epoch 58/250\n",
      "20376/20376 [==============================] - 4s 193us/sample - loss: 0.4273 - val_loss: 0.3630\n",
      "Epoch 59/250\n",
      "20376/20376 [==============================] - 4s 191us/sample - loss: 0.4228 - val_loss: 0.3784\n",
      "Epoch 60/250\n",
      "20376/20376 [==============================] - 4s 192us/sample - loss: 0.4272 - val_loss: 0.3659\n",
      "Epoch 61/250\n",
      "20376/20376 [==============================] - 4s 189us/sample - loss: 0.4225 - val_loss: 0.3724\n",
      "Epoch 62/250\n",
      "20376/20376 [==============================] - 3s 147us/sample - loss: 0.4240 - val_loss: 0.3581\n",
      "Epoch 63/250\n",
      "20376/20376 [==============================] - 3s 140us/sample - loss: 0.4231 - val_loss: 0.3648\n",
      "Epoch 64/250\n",
      "20376/20376 [==============================] - 13s 616us/sample - loss: 0.4240 - val_loss: 0.3623\n",
      "Epoch 65/250\n",
      "20376/20376 [==============================] - 3s 158us/sample - loss: 0.4261 - val_loss: 0.3684\n",
      "Epoch 66/250\n",
      "20376/20376 [==============================] - 3s 166us/sample - loss: 0.4282 - val_loss: 0.3699\n",
      "Epoch 67/250\n",
      "20376/20376 [==============================] - 3s 148us/sample - loss: 0.4263 - val_loss: 0.3691\n",
      "Epoch 68/250\n",
      "20376/20376 [==============================] - 3s 149us/sample - loss: 0.4325 - val_loss: 0.3681\n",
      "Epoch 69/250\n",
      "20376/20376 [==============================] - 3s 151us/sample - loss: 0.4328 - val_loss: 0.3761\n",
      "Epoch 70/250\n",
      "20376/20376 [==============================] - 3s 168us/sample - loss: 0.4309 - val_loss: 0.3642\n",
      "Epoch 71/250\n",
      "20376/20376 [==============================] - 3s 157us/sample - loss: 0.4220 - val_loss: 0.3669\n",
      "Epoch 72/250\n",
      "20376/20376 [==============================] - 3s 163us/sample - loss: 0.4227 - val_loss: 0.3717\n",
      "Epoch 73/250\n",
      "20376/20376 [==============================] - 4s 197us/sample - loss: 0.4264 - val_loss: 0.3665\n",
      "Epoch 74/250\n",
      "20376/20376 [==============================] - 3s 168us/sample - loss: 0.4185 - val_loss: 0.3669\n",
      "Epoch 75/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20376/20376 [==============================] - 3s 159us/sample - loss: 0.4132 - val_loss: 0.3653\n",
      "Epoch 76/250\n",
      "20376/20376 [==============================] - 22s 1ms/sample - loss: 0.4157 - val_loss: 0.3602\n",
      "Epoch 77/250\n",
      "20320/20376 [============================>.] - ETA: 0s - loss: 0.4165\n",
      "Epoch 00077: ReduceLROnPlateau reducing learning rate to 0.0006000000284984708.\n",
      "20376/20376 [==============================] - 23s 1ms/sample - loss: 0.4159 - val_loss: 0.3729\n",
      "Epoch 78/250\n",
      "20376/20376 [==============================] - 23s 1ms/sample - loss: 0.4149 - val_loss: 0.3644\n",
      "Epoch 79/250\n",
      "20376/20376 [==============================] - 26s 1ms/sample - loss: 0.4094 - val_loss: 0.3544\n",
      "Epoch 80/250\n",
      "20376/20376 [==============================] - 25s 1ms/sample - loss: 0.4046 - val_loss: 0.3632\n",
      "Epoch 81/250\n",
      "20376/20376 [==============================] - 27s 1ms/sample - loss: 0.4079 - val_loss: 0.3541\n",
      "Epoch 82/250\n",
      "20376/20376 [==============================] - 24s 1ms/sample - loss: 0.4066 - val_loss: 0.3610\n",
      "Epoch 83/250\n",
      "20376/20376 [==============================] - 3s 158us/sample - loss: 0.4042 - val_loss: 0.3527\n",
      "Epoch 84/250\n",
      "20376/20376 [==============================] - 8s 394us/sample - loss: 0.4032 - val_loss: 0.3506\n",
      "Epoch 85/250\n",
      "20376/20376 [==============================] - 26s 1ms/sample - loss: 0.4004 - val_loss: 0.3529\n",
      "Epoch 86/250\n",
      "20376/20376 [==============================] - 27s 1ms/sample - loss: 0.4015 - val_loss: 0.3535\n",
      "Epoch 87/250\n",
      "20376/20376 [==============================] - 24s 1ms/sample - loss: 0.3988 - val_loss: 0.3551\n",
      "Epoch 88/250\n",
      "20376/20376 [==============================] - 23s 1ms/sample - loss: 0.3982 - val_loss: 0.3568\n",
      "Epoch 89/250\n",
      "20376/20376 [==============================] - 20s 1ms/sample - loss: 0.4003 - val_loss: 0.3643\n",
      "Epoch 90/250\n",
      "20376/20376 [==============================] - 23s 1ms/sample - loss: 0.3975 - val_loss: 0.3529\n",
      "Epoch 91/250\n",
      "20376/20376 [==============================] - 24s 1ms/sample - loss: 0.3996 - val_loss: 0.3554\n",
      "Epoch 92/250\n",
      "20376/20376 [==============================] - 23s 1ms/sample - loss: 0.3988 - val_loss: 0.3509\n",
      "Epoch 93/250\n",
      "20376/20376 [==============================] - 5s 251us/sample - loss: 0.3969 - val_loss: 0.3534\n",
      "Epoch 94/250\n",
      "20376/20376 [==============================] - 8s 374us/sample - loss: 0.3997 - val_loss: 0.3527\n",
      "Epoch 95/250\n",
      "20376/20376 [==============================] - 9s 443us/sample - loss: 0.3970 - val_loss: 0.3541\n",
      "Epoch 96/250\n",
      "20376/20376 [==============================] - 5s 253us/sample - loss: 0.3964 - val_loss: 0.3556\n",
      "Epoch 97/250\n",
      "20376/20376 [==============================] - 6s 287us/sample - loss: 0.3986 - val_loss: 0.3588\n",
      "Epoch 98/250\n",
      "20376/20376 [==============================] - 3s 148us/sample - loss: 0.4008 - val_loss: 0.3556\n",
      "Epoch 99/250\n",
      "20256/20376 [============================>.] - ETA: 0s - loss: 0.3997\n",
      "Epoch 00099: ReduceLROnPlateau reducing learning rate to 0.0003600000170990825.\n",
      "20376/20376 [==============================] - 4s 178us/sample - loss: 0.4006 - val_loss: 0.3529\n",
      "Epoch 100/250\n",
      "20376/20376 [==============================] - 3s 161us/sample - loss: 0.3939 - val_loss: 0.3484\n",
      "Epoch 101/250\n",
      "20376/20376 [==============================] - 3s 161us/sample - loss: 0.3937 - val_loss: 0.3479\n",
      "Epoch 102/250\n",
      "20376/20376 [==============================] - 3s 166us/sample - loss: 0.3908 - val_loss: 0.3493\n",
      "Epoch 103/250\n",
      "20376/20376 [==============================] - 4s 174us/sample - loss: 0.3904 - val_loss: 0.3482\n",
      "Epoch 104/250\n",
      "20376/20376 [==============================] - 21s 1ms/sample - loss: 0.3895 - val_loss: 0.3564\n",
      "Epoch 105/250\n",
      "20376/20376 [==============================] - 19s 955us/sample - loss: 0.3888 - val_loss: 0.3504\n",
      "Epoch 106/250\n",
      "20376/20376 [==============================] - 22s 1ms/sample - loss: 0.3872 - val_loss: 0.3491\n",
      "Epoch 107/250\n",
      "20376/20376 [==============================] - 20s 963us/sample - loss: 0.3860 - val_loss: 0.3471\n",
      "Epoch 108/250\n",
      "20376/20376 [==============================] - 20s 1ms/sample - loss: 0.3869 - val_loss: 0.3481\n",
      "Epoch 109/250\n",
      "20376/20376 [==============================] - 21s 1ms/sample - loss: 0.3850 - val_loss: 0.3494\n",
      "Epoch 110/250\n",
      "20376/20376 [==============================] - 21s 1ms/sample - loss: 0.3861 - val_loss: 0.3452\n",
      "Epoch 111/250\n",
      "20376/20376 [==============================] - 22s 1ms/sample - loss: 0.3850 - val_loss: 0.3477\n",
      "Epoch 112/250\n",
      "20376/20376 [==============================] - 20s 988us/sample - loss: 0.3854 - val_loss: 0.3480\n",
      "Epoch 113/250\n",
      "20376/20376 [==============================] - 18s 890us/sample - loss: 0.3836 - val_loss: 0.3484\n",
      "Epoch 114/250\n",
      "20376/20376 [==============================] - 17s 826us/sample - loss: 0.3861 - val_loss: 0.3548\n",
      "Epoch 115/250\n",
      "20376/20376 [==============================] - 20s 1ms/sample - loss: 0.3847 - val_loss: 0.3515\n",
      "Epoch 116/250\n",
      "20376/20376 [==============================] - 22s 1ms/sample - loss: 0.3843 - val_loss: 0.3482\n",
      "Epoch 117/250\n",
      "20376/20376 [==============================] - 21s 1ms/sample - loss: 0.3833 - val_loss: 0.3484\n",
      "Epoch 118/250\n",
      "20376/20376 [==============================] - 15s 743us/sample - loss: 0.3819 - val_loss: 0.3534\n",
      "Epoch 119/250\n",
      "20376/20376 [==============================] - 3s 155us/sample - loss: 0.3853 - val_loss: 0.3496\n",
      "Epoch 120/250\n",
      "20376/20376 [==============================] - 3s 154us/sample - loss: 0.3857 - val_loss: 0.3464\n",
      "Epoch 121/250\n",
      "20376/20376 [==============================] - 3s 147us/sample - loss: 0.3822 - val_loss: 0.3515\n",
      "Epoch 122/250\n",
      "20376/20376 [==============================] - 3s 142us/sample - loss: 0.3817 - val_loss: 0.3446\n",
      "Epoch 123/250\n",
      "20376/20376 [==============================] - 3s 142us/sample - loss: 0.3823 - val_loss: 0.3519\n",
      "Epoch 124/250\n",
      "20376/20376 [==============================] - 3s 145us/sample - loss: 0.3851 - val_loss: 0.3503\n",
      "Epoch 125/250\n",
      "20376/20376 [==============================] - 3s 142us/sample - loss: 0.3839 - val_loss: 0.3522\n",
      "Epoch 126/250\n",
      "20376/20376 [==============================] - 3s 148us/sample - loss: 0.3820 - val_loss: 0.3514\n",
      "Epoch 127/250\n",
      "20376/20376 [==============================] - 3s 141us/sample - loss: 0.3789 - val_loss: 0.3498\n",
      "Epoch 128/250\n",
      "20376/20376 [==============================] - 3s 147us/sample - loss: 0.3805 - val_loss: 0.3479\n",
      "Epoch 129/250\n",
      "20376/20376 [==============================] - 3s 144us/sample - loss: 0.3815 - val_loss: 0.3501\n",
      "Epoch 130/250\n",
      "20376/20376 [==============================] - 3s 144us/sample - loss: 0.3818 - val_loss: 0.3518\n",
      "Epoch 131/250\n",
      "20376/20376 [==============================] - 3s 143us/sample - loss: 0.3831 - val_loss: 0.3501\n",
      "Epoch 132/250\n",
      "20376/20376 [==============================] - 3s 146us/sample - loss: 0.3860 - val_loss: 0.3495\n",
      "Epoch 133/250\n",
      "20376/20376 [==============================] - 3s 161us/sample - loss: 0.3866 - val_loss: 0.3539\n",
      "Epoch 134/250\n",
      "20376/20376 [==============================] - 3s 154us/sample - loss: 0.3840 - val_loss: 0.3539\n",
      "Epoch 135/250\n",
      "20376/20376 [==============================] - 3s 156us/sample - loss: 0.3798 - val_loss: 0.3485\n",
      "Epoch 136/250\n",
      "20376/20376 [==============================] - 3s 145us/sample - loss: 0.3809 - val_loss: 0.3544\n",
      "Epoch 137/250\n",
      "20256/20376 [============================>.] - ETA: 0s - loss: 0.3817\n",
      "Epoch 00137: ReduceLROnPlateau reducing learning rate to 0.00021600000327453016.\n",
      "20376/20376 [==============================] - 3s 139us/sample - loss: 0.3820 - val_loss: 0.3464\n",
      "Epoch 138/250\n",
      "20376/20376 [==============================] - 3s 151us/sample - loss: 0.3783 - val_loss: 0.3491\n",
      "Epoch 139/250\n",
      "20376/20376 [==============================] - 3s 144us/sample - loss: 0.3770 - val_loss: 0.3519\n",
      "Epoch 140/250\n",
      "20376/20376 [==============================] - 3s 149us/sample - loss: 0.3774 - val_loss: 0.3484\n",
      "Epoch 141/250\n",
      "20376/20376 [==============================] - 3s 145us/sample - loss: 0.3770 - val_loss: 0.3465\n",
      "Epoch 142/250\n",
      "20376/20376 [==============================] - 3s 147us/sample - loss: 0.3790 - val_loss: 0.3435\n",
      "Epoch 143/250\n",
      "20376/20376 [==============================] - 3s 142us/sample - loss: 0.3789 - val_loss: 0.3490\n",
      "Epoch 144/250\n",
      "20376/20376 [==============================] - 3s 142us/sample - loss: 0.3780 - val_loss: 0.3506\n",
      "Epoch 145/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20376/20376 [==============================] - 3s 152us/sample - loss: 0.3786 - val_loss: 0.3486\n",
      "Epoch 146/250\n",
      "20376/20376 [==============================] - 3s 141us/sample - loss: 0.3758 - val_loss: 0.3450\n",
      "Epoch 147/250\n",
      "20376/20376 [==============================] - 3s 143us/sample - loss: 0.3764 - val_loss: 0.3460\n",
      "Epoch 148/250\n",
      "20376/20376 [==============================] - 3s 144us/sample - loss: 0.3783 - val_loss: 0.3497\n",
      "Epoch 149/250\n",
      "20376/20376 [==============================] - 3s 143us/sample - loss: 0.3764 - val_loss: 0.3451\n",
      "Epoch 150/250\n",
      "20376/20376 [==============================] - 3s 139us/sample - loss: 0.3758 - val_loss: 0.3483\n",
      "Epoch 151/250\n",
      "20376/20376 [==============================] - 3s 138us/sample - loss: 0.3741 - val_loss: 0.3496\n",
      "Epoch 152/250\n",
      "20376/20376 [==============================] - 3s 142us/sample - loss: 0.3768 - val_loss: 0.3504\n",
      "Epoch 153/250\n",
      "20376/20376 [==============================] - 3s 146us/sample - loss: 0.3749 - val_loss: 0.3502\n",
      "Epoch 154/250\n",
      "20376/20376 [==============================] - 3s 141us/sample - loss: 0.3757 - val_loss: 0.3500\n",
      "Epoch 155/250\n",
      "20376/20376 [==============================] - 3s 140us/sample - loss: 0.3750 - val_loss: 0.3473\n",
      "Epoch 156/250\n",
      "20376/20376 [==============================] - 3s 152us/sample - loss: 0.3755 - val_loss: 0.3618\n",
      "Epoch 157/250\n",
      "20256/20376 [============================>.] - ETA: 0s - loss: 0.3773\n",
      "Epoch 00157: ReduceLROnPlateau reducing learning rate to 0.00012960000021848827.\n",
      "20376/20376 [==============================] - 3s 144us/sample - loss: 0.3764 - val_loss: 0.3486\n",
      "Epoch 158/250\n",
      "20376/20376 [==============================] - 3s 138us/sample - loss: 0.3728 - val_loss: 0.3481\n",
      "Epoch 159/250\n",
      "20376/20376 [==============================] - 3s 140us/sample - loss: 0.3711 - val_loss: 0.3483\n",
      "Epoch 160/250\n",
      "20376/20376 [==============================] - 3s 154us/sample - loss: 0.3716 - val_loss: 0.3487\n",
      "Epoch 161/250\n",
      "20376/20376 [==============================] - 3s 158us/sample - loss: 0.3708 - val_loss: 0.3504\n",
      "Epoch 162/250\n",
      "20376/20376 [==============================] - 3s 145us/sample - loss: 0.3710 - val_loss: 0.3502\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit(x=[X_lstm_train,X_dense_train],y=y_train, validation_data=[[X_lstm_test,X_dense_test],y_test]\n",
    "          ,epochs=250,callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.]], dtype=float32),\n",
       " array([[0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.]]))"
      ]
     },
     "execution_count": 347,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict([X_lstm[150:160],X_dense[150:160]]),y[150:160]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
